from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import json
from pathlib import Path
from fastapi.responses import FileResponse, JSONResponse
import threading
import schedule
import time
from datetime import datetime, timedelta
import sys
import os
import logging
from typing import Dict, Any, Optional
from collections import defaultdict

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(BASE_DIR))

# !scrapper.pyì˜ í•¨ìˆ˜ë“¤ì„ ìž„í¬íŠ¸
from news_scraper import run_news_pipeline, NewsPipeline

app = FastAPI()

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent.parent
FLUTTER_BUILD_DIR = BASE_DIR / "flutter_ui" / "build" / "web"
ASSETS_DIR = BASE_DIR / "assets"

# assets ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
try:
    ASSETS_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"âœ… assets ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„± ì™„ë£Œ: {ASSETS_DIR}")
except Exception as e:
    logger.error(f"âŒ assets ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„±
DEFAULT_DATA_FILE = ASSETS_DIR / "trend_summary_default.json"
if not DEFAULT_DATA_FILE.exists():
    try:
        default_data = {
            "trend_summary": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤...",
            "candidate_stats": {
                "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
            },
            "total_articles": 0,
            "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘",
            "news_list": []  # ë¹ˆ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        }
        with open(DEFAULT_DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(default_data, f, ensure_ascii=False, indent=2)
        logger.info("âœ… ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# --- CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì „ì—­ ë³€ìˆ˜ ë° ìºì‹œ ê´€ë¦¬ ---
class NewsCache:
    def __init__(self):
        self.latest_data: Optional[Dict[str, Any]] = None
        self.last_update: Optional[datetime] = None
        self.update_count: int = 0
        self.error_count: int = 0
        self.last_error: Optional[str] = None
        self.pipeline = NewsPipeline()

    def update(self, data: Dict[str, Any]):
        self.latest_data = data
        self.last_update = datetime.now()
        self.update_count += 1
        self.error_count = 0
        self.last_error = None

    def record_error(self, error: str):
        self.error_count += 1
        self.last_error = error
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {error}")

    def get_status(self) -> Dict[str, Any]:
        return {
            "last_update": self.last_update.isoformat() if self.last_update else None,
            "update_count": self.update_count,
            "error_count": self.error_count,
            "last_error": self.last_error,
            "is_healthy": self.error_count < 3 and self.last_update is not None
        }

news_cache = NewsCache()

def update_news_cache():
    """assets í´ë”ì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì½ì–´ì™€ ìºì‹œë¥¼ ì—…ë°ì´íŠ¸"""
    try:
        news_files = sorted(
            ASSETS_DIR.glob("trend_summary_*.json"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        if not news_files:
            logger.warning("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            if DEFAULT_DATA_FILE.exists():
                with open(DEFAULT_DATA_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    news_cache.update(data)
                    logger.info("âœ… ê¸°ë³¸ ë°ì´í„°ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            else:
                news_cache.record_error("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            with open(news_files[0], "r", encoding="utf-8") as f:
                data = json.load(f)
                # ê¸°ë³¸ê°’ ì„¤ì •ìœ¼ë¡œ null ë°©ì§€
                processed_data = {
                    "trend_summary": data.get("trend_summary", "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤..."),
                    "candidate_stats": data.get("candidate_stats", {
                        "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                        "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                        "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                    }),
                    "total_articles": data.get("total_articles", 0),
                    "time_range": data.get("time_range", "ë°ì´í„° ìˆ˜ì§‘ ì¤‘"),
                    "news_list": data.get("news_list", [])  # news_list í•„ë“œ ì¶”ê°€
                }
                news_cache.update(processed_data)
                logger.info(f"âœ… ë‰´ìŠ¤ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {news_files[0].name}")
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            news_cache.record_error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            logger.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            news_cache.record_error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            
    except Exception as e:
        news_cache.record_error(str(e))
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

def run_scheduler():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    while True:
        try:
            schedule.run_pending()
            time.sleep(1)
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
            time.sleep(60)

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/status")
async def get_status():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy" if news_cache.get_status()["is_healthy"] else "degraded",
        "cache": news_cache.get_status(),
        "server_time": datetime.now().isoformat(),
        "uptime": str(datetime.now() - news_cache.last_update) if news_cache.last_update else None
    }

@app.get("/news")
async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        if not news_cache.latest_data:
            update_news_cache()
            if not news_cache.latest_data:
                # ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
                if DEFAULT_DATA_FILE.exists():
                    with open(DEFAULT_DATA_FILE, "r", encoding="utf-8") as f:
                        default_data = json.load(f)
                else:
                    default_data = {
                        "trend_summary": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤...",
                        "candidate_stats": {
                            "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                            "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                            "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                        },
                        "total_articles": 0,
                        "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘",
                        "news_list": []  # ë¹ˆ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
                    }
                return {
                    "data": default_data,
                    "metadata": {
                        "last_updated": datetime.now().isoformat(),
                        "next_update": (datetime.now() + timedelta(hours=1)).isoformat(),
                        "status": "using_default"
                    }
                }
        
        # news_list í•„ë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ì¶”ê°€
        if "news_list" not in news_cache.latest_data:
            news_cache.latest_data["news_list"] = []
            
        return {
            "data": news_cache.latest_data,
            "metadata": {
                "last_updated": news_cache.last_update.isoformat(),
                "next_update": (news_cache.last_update + timedelta(hours=1)).isoformat() if news_cache.last_update else None,
                "status": "success"
            }
        }
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {
            "data": {
                "trend_summary": "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "candidate_stats": {
                    "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                },
                "total_articles": 0,
                "time_range": "ì˜¤ë¥˜ ë°œìƒ"
            },
            "metadata": {
                "last_updated": datetime.now().isoformat(),
                "next_update": (datetime.now() + timedelta(hours=1)).isoformat(),
                "status": "error",
                "error": str(e)
            }
        }

@app.post("/refresh")
async def force_refresh(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"""
    background_tasks.add_task(run_news_pipeline)
    return {"message": "ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ì´ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤."}

# --- ì„œë²„ ì‹œìž‘ ì´ë²¤íŠ¸ ---
@app.on_event("startup")
async def startup_event():
    # ì´ˆê¸° ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    try:
        logger.info("ðŸ”„ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì‹œìž‘...")
        update_news_cache()  # ìºì‹œ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
        logger.info("âœ… ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    # 1ì‹œê°„ë§ˆë‹¤ ìˆ˜í–‰í•˜ë˜ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ë§¤ì¼ ì˜¤ì „ 6ì‹œì—ë§Œ ìˆ˜í–‰í•˜ë„ë¡ ë³€ê²½
    schedule.every().day.at("06:00").do(run_news_pipeline)  # ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„
    schedule.every().day.at("06:10").do(lambda: news_cache.pipeline.analyzer.analyze_trends(news_cache.pipeline.temp_storage, "ì „ì¼"))  # ë§¤ì¼ ì˜¤ì „ 6ì‹œ 10ë¶„ì— íŠ¸ë Œë“œ ë¶„ì„
    schedule.every(5).minutes.do(update_news_cache)  # ìºì‹œ ì—…ë°ì´íŠ¸ëŠ” 5ë¶„ë§ˆë‹¤ ìœ ì§€
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    logger.info("ðŸ•’ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ë°ì´í„°ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.")

# --- Flutter ì›¹ ì•± ì œê³µ ---
if not FLUTTER_BUILD_DIR.exists() or not (FLUTTER_BUILD_DIR / "index.html").exists():
    logger.warning(f"Flutter ë¹Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR}")
    
    @app.get("/")
    async def fallback_root():
        return JSONResponse({
            "status": "warning",
            "message": "Flutter UI ë¹Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIëŠ” /news ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "endpoints": {
                "/news": "ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ",
                "/status": "ì„œë²„ ìƒíƒœ í™•ì¸",
                "/refresh": "ìˆ˜ë™ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"
            }
        })
else:
    @app.get("/")
    async def root():
        return FileResponse(str(FLUTTER_BUILD_DIR / "index.html"))

    # ì •ì  íŒŒì¼ ì œê³µ - ê° ë””ë ‰í† ë¦¬ê°€ ì¡´ìž¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ë§ˆìš´íŠ¸
    try:
        if (FLUTTER_BUILD_DIR / "assets").exists():
            app.mount("/assets", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "assets")), name="flutter_assets")
            logger.info(f"âœ… Flutter assets ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'assets'}")
        else:
            logger.warning(f"âš ï¸ Flutter assets ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'assets'}")
    except Exception as e:
        logger.error(f"âŒ assets ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    try:
        if (FLUTTER_BUILD_DIR / "icons").exists():
            app.mount("/icons", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "icons")), name="flutter_icons")
            logger.info(f"âœ… Flutter icons ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'icons'}")
        else:
            logger.warning(f"âš ï¸ Flutter icons ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'icons'}")
    except Exception as e:
        logger.error(f"âŒ icons ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    try:
        if (FLUTTER_BUILD_DIR / "canvaskit").exists():
            app.mount("/canvaskit", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "canvaskit")), name="flutter_canvaskit")
            logger.info(f"âœ… Flutter canvaskit ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'canvaskit'}")
        else:
            logger.warning(f"âš ï¸ Flutter canvaskit ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'canvaskit'}")
    except Exception as e:
        logger.error(f"âŒ canvaskit ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    @app.get("/{path:path}")
    async def serve_flutter_web(path: str):
        file_path = FLUTTER_BUILD_DIR / path
        if file_path.exists():
            return FileResponse(str(file_path))
        return FileResponse(str(FLUTTER_BUILD_DIR / "index.html"))