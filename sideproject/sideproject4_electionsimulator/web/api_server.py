from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import json
from pathlib import Path
from fastapi.responses import FileResponse, JSONResponse
import threading
import schedule
import time
from datetime import datetime, timedelta
import sys
import os
import logging
from typing import Dict, Any, Optional
from collections import defaultdict

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(BASE_DIR))

# !scrapper.pyì˜ í•¨ìˆ˜ë“¤ì„ ìž„í¬íŠ¸
from news_scraper import run_news_pipeline, NewsPipeline

app = FastAPI()

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent.parent
FLUTTER_BUILD_DIR = BASE_DIR / "flutter_ui" / "build" / "web"
ASSETS_DIR = BASE_DIR / "assets"
# ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ì„¤ì • - Flutter ë¹Œë“œ íŒŒì¼ìš©
STATIC_DIR = Path(__file__).resolve().parent / "static"

# assets ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
try:
    ASSETS_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"âœ… assets ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„± ì™„ë£Œ: {ASSETS_DIR}")
except Exception as e:
    logger.error(f"âŒ assets ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# static ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
try:
    STATIC_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"âœ… static ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„± ì™„ë£Œ: {STATIC_DIR}")
except Exception as e:
    logger.error(f"âŒ static ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„±
DEFAULT_DATA_FILE = ASSETS_DIR / "trend_summary_default.json"
if not DEFAULT_DATA_FILE.exists():
    try:
        default_data = {
            "trend_summary": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤...",
            "candidate_stats": {
                "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
            },
            "total_articles": 0,
            "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘",
            "news_list": []  # ë¹ˆ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        }
        with open(DEFAULT_DATA_FILE, "w", encoding="utf-8") as f:
            json.dump(default_data, f, ensure_ascii=False, indent=2)
        logger.info("âœ… ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# --- CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì „ì—­ ë³€ìˆ˜ ë° ìºì‹œ ê´€ë¦¬ ---
class NewsCache:
    def __init__(self):
        self.latest_data: Optional[Dict[str, Any]] = None
        self.last_update: Optional[datetime] = None
        self.update_count: int = 0
        self.error_count: int = 0
        self.last_error: Optional[str] = None
        self.pipeline = NewsPipeline()
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ìƒíƒœ ì¶”ì 
        self.scheduler_running = False
        self.daily_task_last_run = None

    def update(self, data: Dict[str, Any]):
        self.latest_data = data
        self.last_update = datetime.now()
        self.update_count += 1
        self.error_count = 0
        self.last_error = None

    def record_error(self, error: str):
        self.error_count += 1
        self.last_error = error
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {error}")

    def get_status(self) -> Dict[str, Any]:
        return {
            "last_update": self.last_update.isoformat() if self.last_update else None,
            "update_count": self.update_count,
            "error_count": self.error_count,
            "last_error": self.last_error,
            "is_healthy": self.error_count < 3 and self.last_update is not None,
            "scheduler_running": self.scheduler_running,
            "daily_task_last_run": self.daily_task_last_run.isoformat() if self.daily_task_last_run else None
        }

news_cache = NewsCache()

def update_news_cache():
    """assets í´ë”ì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì½ì–´ì™€ ìºì‹œë¥¼ ì—…ë°ì´íŠ¸"""
    try:
        news_files = sorted(
            ASSETS_DIR.glob("trend_summary_*.json"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        if not news_files:
            logger.warning("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            if DEFAULT_DATA_FILE.exists():
                with open(DEFAULT_DATA_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    news_cache.update(data)
                    logger.info("âœ… ê¸°ë³¸ ë°ì´í„°ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            else:
                news_cache.record_error("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            with open(news_files[0], "r", encoding="utf-8") as f:
                data = json.load(f)
                # ê¸°ë³¸ê°’ ì„¤ì •ìœ¼ë¡œ null ë°©ì§€
                processed_data = {
                    "trend_summary": data.get("trend_summary", "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤..."),
                    "candidate_stats": data.get("candidate_stats", {
                        "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                        "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                        "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                    }),
                    "total_articles": data.get("total_articles", 0),
                    "time_range": data.get("time_range", "ë°ì´í„° ìˆ˜ì§‘ ì¤‘"),
                    "news_list": data.get("news_list", [])  # news_list í•„ë“œ ì¶”ê°€
                }
                news_cache.update(processed_data)
                logger.info(f"âœ… ë‰´ìŠ¤ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {news_files[0].name}")
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            news_cache.record_error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            logger.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            news_cache.record_error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            
    except Exception as e:
        news_cache.record_error(str(e))
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

def run_scheduled_news_pipeline():
    """ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ì‹¤í–‰ë˜ëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜"""
    try:
        # ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        now = datetime.now()
        
        if news_cache.daily_task_last_run:
            last_run_date = news_cache.daily_task_last_run.date()
            if last_run_date == now.date():
                logger.info(f"â­ï¸ ì˜¤ëŠ˜({now.date()})ì€ ì´ë¯¸ ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                return
        
        logger.info(f"ðŸ”” ì˜ˆì •ëœ ì¼ì¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìž‘: {now}")
        run_news_pipeline()  # ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹¤í–‰
        news_cache.daily_task_last_run = now
        logger.info(f"âœ… ì¼ì¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {now}")
    except Exception as e:
        logger.error(f"âŒ ì˜ˆì •ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")

def run_scheduler():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    news_cache.scheduler_running = True
    logger.info("ðŸ•’ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ í™•ì¸ (1ì´ˆë³´ë‹¤ íš¨ìœ¨ì )
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
            time.sleep(300)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 5ë¶„ ëŒ€ê¸°

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/status")
async def get_status():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy" if news_cache.get_status()["is_healthy"] else "degraded",
        "cache": news_cache.get_status(),
        "server_time": datetime.now().isoformat(),
        "uptime": str(datetime.now() - news_cache.last_update) if news_cache.last_update else None
    }

@app.get("/news")
async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        if not news_cache.latest_data:
            update_news_cache()
            if not news_cache.latest_data:
                # ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
                if DEFAULT_DATA_FILE.exists():
                    with open(DEFAULT_DATA_FILE, "r", encoding="utf-8") as f:
                        default_data = json.load(f)
                else:
                    default_data = {
                        "trend_summary": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤...",
                        "candidate_stats": {
                            "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                            "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                            "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                        },
                        "total_articles": 0,
                        "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘",
                        "news_list": []  # ë¹ˆ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
                    }
                return {
                    "data": default_data,
                    "metadata": {
                        "last_updated": datetime.now().isoformat(),
                        "next_update": (datetime.now() + timedelta(hours=1)).isoformat(),
                        "status": "using_default"
                    }
                }
        
        # news_list í•„ë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ì¶”ê°€
        if "news_list" not in news_cache.latest_data:
            news_cache.latest_data["news_list"] = []
            
        return {
            "data": news_cache.latest_data,
            "metadata": {
                "last_updated": news_cache.last_update.isoformat(),
                "next_update": (news_cache.last_update + timedelta(hours=24)).isoformat() if news_cache.last_update else None,
                "status": "success"
            }
        }
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {
            "data": {
                "trend_summary": "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "candidate_stats": {
                    "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                },
                "total_articles": 0,
                "time_range": "ì˜¤ë¥˜ ë°œìƒ"
            },
            "metadata": {
                "last_updated": datetime.now().isoformat(),
                "next_update": (datetime.now() + timedelta(hours=24)).isoformat(),
                "status": "error",
                "error": str(e)
            }
        }

@app.post("/refresh")
async def force_refresh(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"""
    # ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œë¶€í„° ìµœì†Œ 1ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸ (ë‚¨ìš© ë°©ì§€)
    if news_cache.daily_task_last_run:
        time_since_last_run = datetime.now() - news_cache.daily_task_last_run
        if time_since_last_run.total_seconds() < 3600:  # 1ì‹œê°„ = 3600ì´ˆ
            return {
                "message": f"ìƒˆë¡œê³ ì¹¨ ìš”ì²­ì´ ë„ˆë¬´ ë¹ˆë²ˆí•©ë‹ˆë‹¤. {3600 - int(time_since_last_run.total_seconds())}ì´ˆ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "status": "rate_limited",
                "last_run": news_cache.daily_task_last_run.isoformat(),
                "next_available": (news_cache.daily_task_last_run + timedelta(hours=1)).isoformat()
            }
    
    background_tasks.add_task(run_news_pipeline)
    return {"message": "ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ì´ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤."}

# --- ì„œë²„ ì‹œìž‘ ì´ë²¤íŠ¸ ---
@app.on_event("startup")
async def startup_event():
    # ì´ˆê¸° ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    try:
        logger.info("ðŸ”„ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì‹œìž‘...")
        update_news_cache()  # ìºì‹œ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
        logger.info("âœ… ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • - ëª…í™•í•˜ê²Œ í•˜ë‚˜ì˜ ìž‘ì—…ë§Œ ì§€ì •
    schedule.clear()  # ê¸°ì¡´ ìŠ¤ì¼€ì¤„ ì´ˆê¸°í™”
    schedule.every().day.at("06:00").do(run_scheduled_news_pipeline)  # ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„
    schedule.every(30).minutes.do(update_news_cache)  # ìºì‹œ ì—…ë°ì´íŠ¸ëŠ” 30ë¶„ë§ˆë‹¤ ìœ ì§€ (5ë¶„â†’30ë¶„ìœ¼ë¡œ ë³€ê²½)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    if not news_cache.scheduler_running:
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()
        logger.info("ðŸ•’ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë§¤ì¼ ì˜¤ì „ 6ì‹œì— ë°ì´í„°ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.")

# --- Flutter ì›¹ ì•± ì œê³µ ---
if not FLUTTER_BUILD_DIR.exists() or not (FLUTTER_BUILD_DIR / "index.html").exists():
    logger.warning(f"Flutter ë¹Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR}")
    
    @app.get("/")
    async def fallback_root():
        return JSONResponse({
            "status": "warning",
            "message": "Flutter UI ë¹Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIëŠ” /news ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "endpoints": {
                "/news": "ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ",
                "/status": "ì„œë²„ ìƒíƒœ í™•ì¸",
                "/refresh": "ìˆ˜ë™ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"
            }
        })
else:
    @app.get("/")
    async def root():
        return FileResponse(str(FLUTTER_BUILD_DIR / "index.html"))

    # ì •ì  íŒŒì¼ ì œê³µ - ê° ë””ë ‰í† ë¦¬ê°€ ì¡´ìž¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ë§ˆìš´íŠ¸
    # 1. Flutter ì›¹ ë¹Œë“œ íŒŒì¼ì„ static ë””ë ‰í† ë¦¬ë¡œ ì œê³µ
    if STATIC_DIR.exists():
        try:
            app.mount("/", StaticFiles(directory=str(STATIC_DIR), html=True), name="static")
            logger.info(f"âœ… ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {STATIC_DIR}")
        except Exception as e:
            logger.error(f"âŒ ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    else:
        logger.warning(f"âš ï¸ ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {STATIC_DIR}")
        # 2. ëŒ€ì•ˆìœ¼ë¡œ Flutter ë¹Œë“œ ë””ë ‰í† ë¦¬ ì§ì ‘ ë§ˆìš´íŠ¸ ì‹œë„
        try:
            app.mount("/", StaticFiles(directory=str(FLUTTER_BUILD_DIR), html=True), name="flutter_web")
            logger.info(f"âœ… Flutter ì›¹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR}")
        except Exception as e:
            logger.error(f"âŒ Flutter ì›¹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    # 3. ê°œë³„ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ (ì—¬ì „ížˆ ìœ íš¨í•˜ì§€ë§Œ ìœ„ì˜ ì „ì²´ ë§ˆìš´íŠ¸ê°€ ë¨¼ì € ì‹œë„ë¨)
    try:
        if (FLUTTER_BUILD_DIR / "assets").exists():
            app.mount("/assets", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "assets")), name="flutter_assets")
            logger.info(f"âœ… Flutter assets ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'assets'}")
        else:
            logger.warning(f"âš ï¸ Flutter assets ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'assets'}")
    except Exception as e:
        logger.error(f"âŒ assets ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    try:
        if (FLUTTER_BUILD_DIR / "icons").exists():
            app.mount("/icons", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "icons")), name="flutter_icons")
            logger.info(f"âœ… Flutter icons ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'icons'}")
        else:
            logger.warning(f"âš ï¸ Flutter icons ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'icons'}")
    except Exception as e:
        logger.error(f"âŒ icons ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    try:
        if (FLUTTER_BUILD_DIR / "canvaskit").exists():
            app.mount("/canvaskit", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "canvaskit")), name="flutter_canvaskit")
            logger.info(f"âœ… Flutter canvaskit ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì™„ë£Œ: {FLUTTER_BUILD_DIR / 'canvaskit'}")
        else:
            logger.warning(f"âš ï¸ Flutter canvaskit ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR / 'canvaskit'}")
    except Exception as e:
        logger.error(f"âŒ canvaskit ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    # 4. ëª¨ë“  íŒŒì¼ì— ëŒ€í•œ ëª…ì‹œì ì¸ MIME íƒ€ìž… ì„¤ì •ì´ ìžˆëŠ” catch-all ë¼ìš°íŠ¸
    @app.get("/{path:path}")
    async def serve_flutter_web(path: str):
        # ë¨¼ì € static ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
        static_path = STATIC_DIR / path
        if static_path.exists():
            # íŒŒì¼ì˜ MIME íƒ€ìž…ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            mime_type = None
            if path.endswith('.js'):
                mime_type = 'application/javascript'
            elif path.endswith('.css'):
                mime_type = 'text/css'
            elif path.endswith('.html'):
                mime_type = 'text/html'
            elif path.endswith('.json'):
                mime_type = 'application/json'
            return FileResponse(str(static_path), media_type=mime_type)
            
        # ë‹¤ìŒìœ¼ë¡œ Flutter ë¹Œë“œ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
        flutter_path = FLUTTER_BUILD_DIR / path
        if flutter_path.exists():
            # íŒŒì¼ì˜ MIME íƒ€ìž…ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            mime_type = None
            if path.endswith('.js'):
                mime_type = 'application/javascript'
            elif path.endswith('.css'):
                mime_type = 'text/css'
            elif path.endswith('.html'):
                mime_type = 'text/html'
            elif path.endswith('.json'):
                mime_type = 'application/json'
            return FileResponse(str(flutter_path), media_type=mime_type)
            
        # íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•Šìœ¼ë©´ index.html ë°˜í™˜
        if (STATIC_DIR / "index.html").exists():
            return FileResponse(str(STATIC_DIR / "index.html"))
        return FileResponse(str(FLUTTER_BUILD_DIR / "index.html"))