from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import json
from pathlib import Path
from fastapi.responses import FileResponse, JSONResponse
import threading
import schedule
import time
from datetime import datetime, timedelta
import sys
import os
import logging
from typing import Dict, Any, Optional
from collections import defaultdict

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(BASE_DIR))

# !scrapper.pyì˜ í•¨ìˆ˜ë“¤ì„ ìž„í¬íŠ¸
from news_scraper import run_news_pipeline, NewsPipeline

app = FastAPI()

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent.parent
FLUTTER_BUILD_DIR = BASE_DIR / "flutter_ui" / "build" / "web"
ASSETS_DIR = BASE_DIR / "assets"
ASSETS_DIR.mkdir(parents=True, exist_ok=True)

# --- CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì • ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì „ì—­ ë³€ìˆ˜ ë° ìºì‹œ ê´€ë¦¬ ---
class NewsCache:
    def __init__(self):
        self.latest_data: Optional[Dict[str, Any]] = None
        self.last_update: Optional[datetime] = None
        self.update_count: int = 0
        self.error_count: int = 0
        self.last_error: Optional[str] = None
        self.pipeline = NewsPipeline()

    def update(self, data: Dict[str, Any]):
        self.latest_data = data
        self.last_update = datetime.now()
        self.update_count += 1
        self.error_count = 0
        self.last_error = None

    def record_error(self, error: str):
        self.error_count += 1
        self.last_error = error
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {error}")

    def get_status(self) -> Dict[str, Any]:
        return {
            "last_update": self.last_update.isoformat() if self.last_update else None,
            "update_count": self.update_count,
            "error_count": self.error_count,
            "last_error": self.last_error,
            "is_healthy": self.error_count < 3 and self.last_update is not None
        }

news_cache = NewsCache()

def update_news_cache():
    """assets í´ë”ì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì½ì–´ì™€ ìºì‹œë¥¼ ì—…ë°ì´íŠ¸"""
    try:
        news_files = sorted(
            ASSETS_DIR.glob("trend_summary_*.json"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        if not news_files:
            news_cache.record_error("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        with open(news_files[0], "r", encoding="utf-8") as f:
            data = json.load(f)
            # ê¸°ë³¸ê°’ ì„¤ì •ìœ¼ë¡œ null ë°©ì§€
            processed_data = {
                "trend_summary": data.get("trend_summary", ""),
                "candidate_stats": data.get("candidate_stats", {
                    "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                }),
                "total_articles": data.get("total_articles", 0),
                "time_range": data.get("time_range", "")
            }
            news_cache.update(processed_data)
            logger.info(f"âœ… ë‰´ìŠ¤ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {news_files[0].name}")
            
    except Exception as e:
        news_cache.record_error(str(e))
        logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

def run_scheduler():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    while True:
        try:
            schedule.run_pending()
            time.sleep(1)
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
            time.sleep(60)

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/status")
async def get_status():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy" if news_cache.get_status()["is_healthy"] else "degraded",
        "cache": news_cache.get_status(),
        "server_time": datetime.now().isoformat(),
        "uptime": str(datetime.now() - news_cache.last_update) if news_cache.last_update else None
    }

@app.get("/news")
async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    if not news_cache.latest_data:
        update_news_cache()
        if not news_cache.latest_data:
            # ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
            default_data = {
                "trend_summary": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ìž…ë‹ˆë‹¤...",
                "candidate_stats": {
                    "ì´ìž¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                    "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
                },
                "total_articles": 0,
                "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘"
            }
            return {
                "data": default_data,
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "next_update": (datetime.now() + timedelta(hours=1)).isoformat()
                }
            }
    
    return {
        "data": news_cache.latest_data,
        "metadata": {
            "last_updated": news_cache.last_update.isoformat(),
            "next_update": (news_cache.last_update + timedelta(hours=1)).isoformat() if news_cache.last_update else None
        }
    }

@app.post("/refresh")
async def force_refresh(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"""
    background_tasks.add_task(run_news_pipeline)
    return {"message": "ë‰´ìŠ¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ì´ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤."}

# --- ì„œë²„ ì‹œìž‘ ì´ë²¤íŠ¸ ---
@app.on_event("startup")
async def startup_event():
    # ì´ˆê¸° ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
    update_news_cache()
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    schedule.every(1).hours.do(run_news_pipeline)
    schedule.every(5).minutes.do(update_news_cache)
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    logger.info("ðŸ•’ ë‰´ìŠ¤ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- Flutter ì›¹ ì•± ì œê³µ ---
if not FLUTTER_BUILD_DIR.exists() or not (FLUTTER_BUILD_DIR / "index.html").exists():
    logger.warning(f"Flutter ë¹Œë“œ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_BUILD_DIR}")
    
    @app.get("/")
    async def fallback_root():
        return JSONResponse({
            "status": "warning",
            "message": "Flutter UI ë¹Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. APIëŠ” /news ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "endpoints": {
                "/news": "ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ",
                "/status": "ì„œë²„ ìƒíƒœ í™•ì¸",
                "/refresh": "ìˆ˜ë™ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"
            }
        })
else:
    @app.get("/")
    async def root():
        return FileResponse(FLUTTER_BUILD_DIR / "index.html")

    # ì •ì  íŒŒì¼ ì œê³µ
    app.mount("/assets", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "assets")), name="flutter_assets")
    app.mount("/icons", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "icons")), name="flutter_icons")
    app.mount("/canvaskit", StaticFiles(directory=str(FLUTTER_BUILD_DIR / "canvaskit")), name="flutter_canvaskit")
    
    @app.get("/{path:path}")
    async def serve_flutter_web(path: str):
        file_path = FLUTTER_BUILD_DIR / path
        if file_path.exists():
            return FileResponse(str(file_path))
        return FileResponse(str(FLUTTER_BUILD_DIR / "index.html"))