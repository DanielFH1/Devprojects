"""
ëŒ€ì„  ì‹œë®¬ë ˆì´í„° API ì„œë²„
- ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
- Flutter ì›¹ ì•± ì„œë¹™
- ì‹¤ì‹œê°„ ë°ì´í„° ìºì‹±
"""

import os
import sys
import json
import time
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from contextlib import asynccontextmanager

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

import uvicorn
from fastapi import FastAPI, BackgroundTasks, HTTPException, Request, Response
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware

import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# news_scraper ëª¨ë“ˆ import (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
try:
    from news_scraper import NewsPipeline, rank_news_by_importance
    NEWS_SCRAPER_AVAILABLE = True
    logger.info("âœ… news_scraper ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    logger.error(f"âŒ news_scraper ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    NEWS_SCRAPER_AVAILABLE = False
    
    # ë”ë¯¸ í´ë˜ìŠ¤ ìƒì„±
    class NewsPipeline:
        def __init__(self):
            pass
        def run_daily_collection(self):
            logger.warning("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def rank_news_by_importance(news_data, limit=30):
        return news_data[:limit]

# === ìƒìˆ˜ ë° ì„¤ì • ===
ASSETS_DIR = parent_dir / "assets"
ASSETS_DIR.mkdir(parents=True, exist_ok=True)

DEFAULT_DATA_FILE = ASSETS_DIR / "trend_summary_default.json"

# Render.com ì˜êµ¬ ì €ì¥ì†Œ ì„¤ì •
PERSISTENT_DIR = None
if os.environ.get('RENDER') == 'true':
    PERSISTENT_DIR = Path("/opt/render/project/src/persistent_data")
    PERSISTENT_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"ğŸ“‚ Render.com ì˜êµ¬ ì €ì¥ì†Œ ì„¤ì •: {PERSISTENT_DIR}")

# Flutter ì›¹ ì•± ê²½ë¡œ
FLUTTER_WEB_DIR = parent_dir / "flutter_ui/web"
logger.info(f"ğŸ“‚ Flutter ì›¹ ë””ë ‰í† ë¦¬ ê²½ë¡œ: {FLUTTER_WEB_DIR}")
logger.info(f"ğŸ“‚ Flutter ì›¹ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {FLUTTER_WEB_DIR.exists()}")

# ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
if FLUTTER_WEB_DIR.exists():
    files = list(FLUTTER_WEB_DIR.iterdir())
    logger.info(f"ğŸ“‚ Flutter ì›¹ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡: {[f.name for f in files]}")
else:
    logger.error(f"âŒ Flutter ì›¹ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FLUTTER_WEB_DIR}")
    # ëŒ€ì•ˆ ê²½ë¡œë“¤ í™•ì¸
    alt_paths = [
        parent_dir / "flutter_ui/build/web",
        Path("flutter_ui/web"),
        Path("flutter_ui/build/web")
    ]
    for alt_path in alt_paths:
        if alt_path.exists():
            logger.info(f"âœ… ëŒ€ì•ˆ ê²½ë¡œ ë°œê²¬: {alt_path}")
            FLUTTER_WEB_DIR = alt_path
            break

# === ë‰´ìŠ¤ ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤ ===
class NewsCache:
    """ë‰´ìŠ¤ ë°ì´í„° ìºì‹œ ê´€ë¦¬"""
    
    def __init__(self):
        self.latest_data: Optional[Dict[str, Any]] = None
        self.last_update: Optional[datetime] = None
        self.update_count: int = 0
        self.error_count: int = 0
        self.last_error: Optional[str] = None
        self.pipeline = NewsPipeline()
        self.initial_fetch_done = False
        self.final_collection_completed = False  # ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ í”Œë˜ê·¸

    def update(self, data: Dict[str, Any]) -> None:
        """ìºì‹œ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        self.latest_data = data
        self.last_update = datetime.now()
        self.update_count += 1
        self.error_count = 0
        self.last_error = None
        logger.info(f"âœ… ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ (#{self.update_count})")

    def record_error(self, error: str) -> None:
        """ì˜¤ë¥˜ ê¸°ë¡"""
        self.error_count += 1
        self.last_error = error
        logger.error(f"âŒ ìºì‹œ ì˜¤ë¥˜ #{self.error_count}: {error}")

    def get_status(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ë°˜í™˜"""
        return {
            "last_update": self.last_update.isoformat() if self.last_update else None,
            "update_count": self.update_count,
            "error_count": self.error_count,
            "last_error": self.last_error,
            "is_healthy": self.error_count < 3 and self.last_update is not None,
            "initial_fetch_done": self.initial_fetch_done,
            "final_collection_completed": self.final_collection_completed
        }

    def is_today_data(self) -> bool:
        """í˜„ì¬ ìºì‹œ ë°ì´í„°ê°€ ì˜¤ëŠ˜ ê²ƒì¸ì§€ í™•ì¸"""
        if not self.latest_data:
            return False
        
        today = datetime.now().strftime("%Y-%m-%d")
        time_range = self.latest_data.get("time_range", "")
        return today in time_range

# === íŒŒì¼ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ===
class FileManager:
    """íŒŒì¼ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def extract_datetime_from_filename(filepath: Path) -> datetime:
        """íŒŒì¼ëª…ì—ì„œ ë‚ ì§œì‹œê°„ ì¶”ì¶œ"""
        try:
            # trend_summary_2025-05-26_13-03.json í˜•ì‹ì—ì„œ ë‚ ì§œì‹œê°„ ì¶”ì¶œ
            parts = filepath.stem.split('_')
            if len(parts) >= 3:
                date_str = parts[2]  # 2025-05-26
                time_str = parts[3] if len(parts) > 3 else "00-00"  # 13-03
                datetime_str = f"{date_str} {time_str.replace('-', ':')}"
                return datetime.strptime(datetime_str, "%Y-%m-%d %H:%M")
        except Exception:
            pass
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ íŒŒì¼ ìˆ˜ì • ì‹œê°„ ì‚¬ìš©
        return datetime.fromtimestamp(filepath.stat().st_mtime)

    @staticmethod
    def find_latest_news_file() -> Optional[Path]:
        """ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ ì°¾ê¸°"""
        # ê¸°ë³¸ íŒŒì¼ ì œì™¸í•˜ê³  ë‚ ì§œê°€ í¬í•¨ëœ íŒŒì¼ë“¤ë§Œ ì°¾ê¸°
        news_files = [
            f for f in ASSETS_DIR.glob("trend_summary_*.json")
            if f.name != "trend_summary_default.json"
        ]
        
        if not news_files:
            return None
            
        try:
            # ë‚ ì§œì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
            latest_file = sorted(
                news_files,
                key=FileManager.extract_datetime_from_filename,
                reverse=True
            )[0]
            logger.info(f"ğŸ“‚ ìµœì‹  ë‚ ì§œ íŒŒì¼ ë°œê²¬: {latest_file}")
            return latest_file
        except Exception as e:
            # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ í´ë°±
            latest_file = sorted(news_files, key=lambda p: p.stat().st_mtime, reverse=True)[0]
            logger.warning(f"âš ï¸ ë‚ ì§œ ê¸°ì¤€ ì •ë ¬ ì‹¤íŒ¨, ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ ì‚¬ìš©: {str(e)}")
            return latest_file

    @staticmethod
    def get_today_files() -> List[Path]:
        """ì˜¤ëŠ˜ ë‚ ì§œì˜ íŒŒì¼ë“¤ ë°˜í™˜"""
        today = datetime.now().strftime("%Y-%m-%d")
        return list(ASSETS_DIR.glob(f"trend_summary_{today}_*.json"))

    @staticmethod
    def load_json_file(filepath: Path) -> Optional[Dict[str, Any]]:
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {filepath}: {str(e)}")
            return None

# === ë°ì´í„° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ===
class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def create_default_data(message: str = "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...") -> Dict[str, Any]:
        """ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ìƒì„±"""
        current_time = datetime.now()
        return {
            "trend_summary": message,
            "candidate_stats": {
                "ì´ì¬ëª…": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ê¹€ë¬¸ìˆ˜": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0},
                "ì´ì¤€ì„": {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
            },
            "total_articles": 0,
            "time_range": f"{current_time.strftime('%Y-%m-%d')} ì—…ë°ì´íŠ¸",
            "news_list": []
        }

    @staticmethod
    def process_news_data(data: Dict[str, Any]) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ë° ì •ê·œí™”"""
        processed_data = {
            "trend_summary": data.get("trend_summary", "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."),
            "candidate_stats": data.get("candidate_stats", DataProcessor.create_default_data()["candidate_stats"]),
            "total_articles": data.get("total_articles", 0),
            "time_range": data.get("time_range", "ë°ì´í„° ìˆ˜ì§‘ ì¤‘"),
            "news_list": data.get("news_list", [])
        }
        
        # ë‰´ìŠ¤ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¤‘ìš”ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        if processed_data["news_list"]:
            try:
                sorted_news = rank_news_by_importance(processed_data["news_list"], limit=100)
                processed_data["news_list"] = sorted_news
                logger.info(f"âœ… ë‰´ìŠ¤ ë°ì´í„° ì¤‘ìš”ë„ ì •ë ¬ ì™„ë£Œ: {len(sorted_news)}ê°œ")
            except Exception as e:
                logger.error(f"âŒ ë‰´ìŠ¤ ì •ë ¬ ì˜¤ë¥˜: {str(e)}")
        
        return processed_data

# === ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ===
news_cache = NewsCache()
file_manager = FileManager()
data_processor = DataProcessor()

# === ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ ===
def update_news_cache() -> None:
    """ë‰´ìŠ¤ ìºì‹œ ì—…ë°ì´íŠ¸"""
    try:
        # ìµœì‹  íŒŒì¼ ì°¾ê¸°
        latest_file = file_manager.find_latest_news_file()
        
        # ì˜êµ¬ ì €ì¥ì†Œì—ì„œ í™•ì¸
        if not latest_file and PERSISTENT_DIR and PERSISTENT_DIR.exists():
            latest_link = PERSISTENT_DIR / "trend_summary_latest.json"
            if latest_link.exists():
                latest_file = latest_link
                logger.info(f"ğŸ“‚ ì˜êµ¬ ì €ì¥ì†Œì—ì„œ ìµœì‹  íŒŒì¼ ë°œê²¬: {latest_file}")
                
                # ì˜êµ¬ ì €ì¥ì†Œì˜ íŒŒì¼ì„ assetsì— ë³µì‚¬
                dest_file = ASSETS_DIR / f"trend_summary_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.json"
                shutil.copy(latest_file, dest_file)
                logger.info(f"ğŸ“‹ ì˜êµ¬ ì €ì¥ì†Œì˜ íŒŒì¼ì„ assetsì— ë³µì‚¬: {dest_file.name}")
                latest_file = dest_file
        
        # ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©
        if not latest_file and DEFAULT_DATA_FILE.exists():
            latest_file = DEFAULT_DATA_FILE
            logger.warning("âš ï¸ ë‚ ì§œê°€ í¬í•¨ëœ ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì²˜ë¦¬
        if latest_file:
            data = file_manager.load_json_file(latest_file)
            if data:
                processed_data = data_processor.process_news_data(data)
                news_cache.update(processed_data)
                logger.info(f"âœ… ë‰´ìŠ¤ ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {latest_file.name}")
            else:
                news_cache.record_error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {latest_file}")
        else:
            news_cache.record_error("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        news_cache.record_error(str(e))
        logger.error(f"âŒ ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

# === ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ===
def force_news_collection() -> bool:
    """ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
    if not NEWS_SCRAPER_AVAILABLE:
        logger.warning("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return False
        
    if news_cache.final_collection_completed:
        logger.info("ğŸš« ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    try:
        logger.info("ğŸ”¥ ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤... (200ê°œ ê¸°ì‚¬ ëª©í‘œ)")
        
        # ê°•ì œ ì‹¤í–‰ ëª¨ë“œ í™œì„±í™”
        os.environ['FORCE_NEWS_COLLECTION'] = 'true'
        
        # ìƒíƒœ ì´ˆê¸°í™”
        news_cache.initial_fetch_done = False
        
        # ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰
        news_cache.pipeline.run_daily_collection()
        
        # í™˜ê²½ë³€ìˆ˜ í•´ì œ
        os.environ.pop('FORCE_NEWS_COLLECTION', None)
        
        # ìˆ˜ì§‘ í›„ ìºì‹œ ì—…ë°ì´íŠ¸
        today_files = file_manager.get_today_files()
        if today_files:
            newest_file = sorted(today_files, key=lambda p: p.stat().st_mtime, reverse=True)[0]
            logger.info(f"âœ… ìƒˆë¡œ ìƒì„±ëœ ì˜¤ëŠ˜ íŒŒì¼ ë°œê²¬: {newest_file}")
        
        update_news_cache()
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        news_cache.initial_fetch_done = True
        news_cache.final_collection_completed = True
        
        logger.info("âœ… ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ - ë” ì´ìƒ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        os.environ.pop('FORCE_NEWS_COLLECTION', None)
        news_cache.final_collection_completed = True  # ì‹¤íŒ¨í•´ë„ ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•ŠìŒ
        return False

# === ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ë¥¼ lifespanìœ¼ë¡œ ë³€ê²½ ===
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™” - ë”± í•œë²ˆë§Œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    try:
        logger.info("ğŸš€ ì„œë²„ ì‹œì‘ - ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ ì´ˆê¸°í™” ì¤‘...")
        
        # ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ëŠ¥ ìƒíƒœ í™•ì¸
        if not NEWS_SCRAPER_AVAILABLE:
            logger.warning("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤.")
            # ê¸°ë³¸ ë°ì´í„°ë¡œ ìºì‹œ ì´ˆê¸°í™”
            default_data = data_processor.create_default_data("ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ëŠ¥ì´ ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            news_cache.update(default_data)
            yield
            return
        
        # ìºì‹œ ì´ˆê¸° ì—…ë°ì´íŠ¸
        update_news_cache()
        logger.info("âœ… ì´ˆê¸° ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ ì½”ë“œ ëª¨ë‘ ì œê±°
        # ëŒ€ì‹  ì„œë²„ ì‹œì‘ì‹œ ë”± í•œë²ˆë§Œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰
        
        today = datetime.now().strftime("%Y-%m-%d")
        today_files = file_manager.get_today_files()
        
        logger.info(f"ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {today}")
        logger.info(f"ğŸ“‚ ì˜¤ëŠ˜ ìƒì„±ëœ íŒŒì¼ ê°œìˆ˜: {len(today_files)}")
        
        # ìµœì¢… ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì‹¤í–‰
        if not news_cache.final_collection_completed:
            logger.info("ğŸ”„ ìµœì¢… ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (200ê°œ ê¸°ì‚¬ ëª©í‘œ)")
            import threading
            collection_thread = threading.Thread(target=force_news_collection, daemon=False)
            collection_thread.start()
            
            # ìˆ˜ì§‘ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ìµœëŒ€ 10ë¶„ ëŒ€ê¸°
            logger.info("â³ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... (ìµœëŒ€ 10ë¶„)")
            collection_thread.join(timeout=600)  # 10ë¶„ ëŒ€ê¸°
            
            if collection_thread.is_alive():
                logger.warning("âš ï¸ ë‰´ìŠ¤ ìˆ˜ì§‘ì´ 10ë¶„ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                logger.info("âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            logger.info("ğŸ ìµœì¢… ìˆ˜ì§‘ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        logger.info("âœ… ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ ì™„ë£Œ")
        logger.info("ğŸš« ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ì´ìƒ ìë™ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        yield  # ì„œë²„ ì‹¤í–‰
        
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
        try:
            default_data = data_processor.create_default_data(f"ì„œë²„ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            news_cache.update(default_data)
            news_cache.final_collection_completed = True
            logger.info("ğŸ”„ ê¸°ë³¸ ë°ì´í„°ë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e2:
            logger.error(f"âŒ ê¸°ë³¸ ë°ì´í„° ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {str(e2)}")
        
        yield  # ì„œë²„ ì‹¤í–‰

# === FastAPI ì•± ì„¤ì • ===
app = FastAPI(
    title="ëŒ€ì„  ì‹œë®¬ë ˆì´í„° API",
    description="2025ë…„ ëŒ€ì„  ë‰´ìŠ¤ ë¶„ì„ ë° ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„°",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • - ë” ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
allowed_origins = [
    "https://electionsimulatorwebservice.onrender.com",
    "https://sideproject4-electionsimulator.onrender.com",  # ì´ì „ ë„ë©”ì¸ë„ í—ˆìš©
    "http://localhost:10000",
    "http://127.0.0.1:10000",
    "*"  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ê°œë°œìš©)
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)

# CORS í—¤ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def add_cors_headers(request: Request, call_next):
    response = await call_next(request)
    
    # ëª…ì‹œì ì¸ CORS í—¤ë” ì¶”ê°€
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
    response.headers["Access-Control-Allow-Headers"] = "*"
    response.headers["Access-Control-Expose-Headers"] = "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    
    return response

# OPTIONS ìš”ì²­ ì²˜ë¦¬
@app.options("/{path:path}")
async def options_handler(path: str):
    return JSONResponse(
        content={"message": "OK"},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Expose-Headers": "*",
            "Access-Control-Allow-Credentials": "true",
        }
    )

# === API ì—”ë“œí¬ì¸íŠ¸ ===
@app.get("/api/status")
async def get_status():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    now = datetime.now()
    today = now.strftime("%Y-%m-%d")
    today_files = file_manager.get_today_files()
    cache_status = news_cache.get_status()
    
    return {
        "status": "healthy" if cache_status["is_healthy"] else "degraded",
        "server_time": now.isoformat(),
        "timezone": "UTC",
        "cache": cache_status,
        "scheduler_status": "DISABLED - ìµœì¢… ìˆ˜ì§‘ ëª¨ë“œ",
        "collection_mode": "ONE_TIME_FINAL",
        "files": {
            "today_files_count": len(today_files),
            "today_files": [f.name for f in today_files],
            "latest_file": file_manager.find_latest_news_file().name if file_manager.find_latest_news_file() else None,
        },
        "data_status": {
            "has_today_data": news_cache.is_today_data(),
            "news_count": len(news_cache.latest_data.get("news_list", [])) if news_cache.latest_data else 0,
            "time_range": news_cache.latest_data.get("time_range", "ì—†ìŒ") if news_cache.latest_data else "ì—†ìŒ",
            "final_collection_completed": news_cache.final_collection_completed
        }
    }

@app.get("/api/trend-summary")
async def get_news_data():
    """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ìºì‹œì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
        if not news_cache.latest_data:
            update_news_cache()
        
        # ì—¬ì „íˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
        if not news_cache.latest_data:
            default_data = data_processor.create_default_data()
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘
            if not news_cache.initial_fetch_done:
                threading.Thread(target=force_news_collection, daemon=True).start()
                news_cache.initial_fetch_done = True
            
            return default_data
        
        # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ì•„ë‹ˆë©´ ìƒˆë¡œ ìˆ˜ì§‘
        if not news_cache.is_today_data():
            logger.warning("âš ï¸ ìºì‹œì˜ ë°ì´í„°ê°€ ì˜¤ëŠ˜ ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ìƒˆë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            threading.Thread(target=force_news_collection, daemon=True).start()
        
        return news_cache.latest_data
        
    except Exception as e:
        logger.error(f"âŒ ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/prediction")
async def get_prediction_data():
    """ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ìºì‹œì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
        if not news_cache.latest_data:
            update_news_cache()
        
        # ê¸°ë³¸ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
        if not news_cache.latest_data:
            return {
                "predictions": {
                    "ì´ì¬ëª…": 35.0,
                    "ê¹€ë¬¸ìˆ˜": 30.0,
                    "ì´ì¤€ì„": 25.0
                },
                "analysis": "ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "total_articles": 0,
                "time_range": "ë°ì´í„° ìˆ˜ì§‘ ì¤‘"
            }
        
        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ ìƒì„±
        candidate_stats = news_cache.latest_data.get("candidate_stats", {})
        total_articles = news_cache.latest_data.get("total_articles", 0)
        
        # ê°„ë‹¨í•œ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ (ê°ì„± ë¶„ì„ ê¸°ë°˜)
        predictions = {}
        base_score = 30.0  # ê¸°ë³¸ ì ìˆ˜
        
        for candidate, stats in candidate_stats.items():
            positive = stats.get("ê¸ì •", 0)
            negative = stats.get("ë¶€ì •", 0)
            neutral = stats.get("ì¤‘ë¦½", 0)
            total = positive + negative + neutral
            
            if total > 0:
                sentiment_score = (positive - negative) / total * 10
                predictions[candidate] = max(10.0, min(50.0, base_score + sentiment_score))
            else:
                predictions[candidate] = base_score
        
        # ì •ê·œí™” (ì´í•© 100%)
        total_pred = sum(predictions.values())
        if total_pred > 0:
            predictions = {k: (v / total_pred) * 100 for k, v in predictions.items()}
        
        return {
            "predictions": predictions,
            "analysis": news_cache.latest_data.get("trend_summary", "ë¶„ì„ ì¤‘..."),
            "total_articles": total_articles,
            "time_range": news_cache.latest_data.get("time_range", "")
        }
        
    except Exception as e:
        logger.error(f"âŒ ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/refresh")
async def force_refresh(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ - ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ í›„ì—ëŠ” ë¹„í™œì„±í™”"""
    if news_cache.final_collection_completed:
        return {
            "message": "ìµœì¢… ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì–´ ë” ì´ìƒ ìƒˆë¡œê³ ì¹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "status": "disabled",
            "reason": "final_collection_completed"
        }
    
    logger.info("ğŸ”„ ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ìš”ì²­")
    background_tasks.add_task(force_news_collection)
    
    return {
        "message": "ìµœì¢… ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "status": "started",
        "estimated_completion": (datetime.now() + timedelta(minutes=5)).isoformat()
    }

@app.post("/api/update-cache")
async def force_update_cache():
    """ìºì‹œ ê°•ì œ ì—…ë°ì´íŠ¸"""
    try:
        logger.info("ğŸ”„ ìºì‹œ ê°•ì œ ì—…ë°ì´íŠ¸ ìš”ì²­")
        update_news_cache()
        
        if news_cache.latest_data:
            return {
                "message": "ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "status": "success",
                "last_updated": news_cache.last_update.isoformat() if news_cache.last_update else None,
                "news_count": len(news_cache.latest_data.get("news_list", [])),
                "time_range": news_cache.latest_data.get("time_range", "ì•Œ ìˆ˜ ì—†ìŒ")
            }
        else:
            return {
                "message": "ìºì‹œ ì—…ë°ì´íŠ¸ëŠ” ì™„ë£Œë˜ì—ˆì§€ë§Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "status": "no_data"
            }
    except Exception as e:
        logger.error(f"âŒ ìºì‹œ ê°•ì œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return {"message": f"ìºì‹œ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}", "status": "error"}

@app.post("/api/force-today-collection")
async def force_today_collection(background_tasks: BackgroundTasks):
    """ì˜¤ëŠ˜ ë°ì´í„° ê°•ì œ ìˆ˜ì§‘ - ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ í›„ì—ëŠ” ë¹„í™œì„±í™”"""
    if news_cache.final_collection_completed:
        return {
            "message": "ìµœì¢… ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì–´ ë” ì´ìƒ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "status": "disabled",
            "reason": "final_collection_completed"
        }
        
    try:
        today = datetime.now().strftime("%Y-%m-%d")
        logger.info(f"ğŸ”¥ ì˜¤ëŠ˜({today}) ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­")
        
        background_tasks.add_task(force_news_collection)
        
        return {
            "message": f"ì˜¤ëŠ˜({today}) ìµœì¢… ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "status": "started",
            "target_date": today,
            "estimated_completion": (datetime.now() + timedelta(minutes=5)).isoformat(),
            "note": "ì´ê²ƒì´ ë§ˆì§€ë§‰ ìˆ˜ì§‘ì…ë‹ˆë‹¤."
        }
    except Exception as e:
        logger.error(f"âŒ ì˜¤ëŠ˜ ë°ì´í„° ê°•ì œ ìˆ˜ì§‘ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        return {"message": f"ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {str(e)}", "status": "error"}

# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤ë„ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
@app.get("/status")
async def get_status_legacy():
    """ì„œë²„ ìƒíƒœ í™•ì¸ (ë ˆê±°ì‹œ)"""
    return await get_status()

@app.get("/news")
async def get_news_data_legacy():
    """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ (ë ˆê±°ì‹œ)"""
    result = await get_news_data()
    return {
        "data": result,
        "metadata": {
            "last_updated": news_cache.last_update.isoformat() if news_cache.last_update else datetime.now().isoformat(),
            "status": "success"
        }
    }

@app.post("/refresh")
async def force_refresh_legacy(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ (ë ˆê±°ì‹œ)"""
    return await force_refresh(background_tasks)

@app.post("/update-cache")
async def force_update_cache_legacy():
    """ìºì‹œ ê°•ì œ ì—…ë°ì´íŠ¸ (ë ˆê±°ì‹œ)"""
    return await force_update_cache()

@app.post("/force-today-collection")
async def force_today_collection_legacy(background_tasks: BackgroundTasks):
    """ì˜¤ëŠ˜ ë°ì´í„° ê°•ì œ ìˆ˜ì§‘ (ë ˆê±°ì‹œ)"""
    return await force_today_collection(background_tasks)

# === Flutter ì›¹ ì•± ì„œë¹™ ===
if FLUTTER_WEB_DIR.exists():
    # ì •ì  íŒŒì¼ ì„œë¹™
    app.mount("/assets", StaticFiles(directory=str(FLUTTER_WEB_DIR / "assets")), name="assets")
    app.mount("/canvaskit", StaticFiles(directory=str(FLUTTER_WEB_DIR / "canvaskit")), name="canvaskit")
    app.mount("/icons", StaticFiles(directory=str(FLUTTER_WEB_DIR / "icons")), name="icons")
    
    # ê°œë³„ íŒŒì¼ë“¤ ì„œë¹™
    @app.get("/main.dart.js")
    async def serve_main_dart_js():
        return FileResponse(str(FLUTTER_WEB_DIR / "main.dart.js"), media_type="application/javascript")
    
    @app.get("/flutter.js")
    async def serve_flutter_js():
        return FileResponse(str(FLUTTER_WEB_DIR / "flutter.js"), media_type="application/javascript")
    
    @app.get("/flutter_bootstrap.js")
    async def serve_flutter_bootstrap_js():
        return FileResponse(str(FLUTTER_WEB_DIR / "flutter_bootstrap.js"), media_type="application/javascript")
    
    @app.get("/flutter_service_worker.js")
    async def serve_flutter_service_worker():
        return FileResponse(str(FLUTTER_WEB_DIR / "flutter_service_worker.js"), media_type="application/javascript")
    
    @app.get("/manifest.json")
    async def serve_manifest():
        return FileResponse(str(FLUTTER_WEB_DIR / "manifest.json"), media_type="application/json")
    
    @app.get("/version.json")
    async def serve_version():
        return FileResponse(str(FLUTTER_WEB_DIR / "version.json"), media_type="application/json")
    
    @app.get("/favicon.png")
    async def serve_favicon():
        return FileResponse(str(FLUTTER_WEB_DIR / "favicon.png"), media_type="image/png")
    
    # ë©”ì¸ í˜ì´ì§€
    @app.get("/")
    async def root():
        return FileResponse(str(FLUTTER_WEB_DIR / "index.html"), media_type="text/html")
    
    # ëª¨ë“  ë‹¤ë¥¸ ê²½ë¡œëŠ” Flutter ì•±ìœ¼ë¡œ ë¼ìš°íŒ… (SPA ì§€ì›)
    @app.get("/{path:path}")
    async def serve_flutter_web(path: str):
        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        file_path = FLUTTER_WEB_DIR / path
        if file_path.exists() and file_path.is_file():
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ MIME íƒ€ì… ì„¤ì •
            if path.endswith('.js'):
                return FileResponse(str(file_path), media_type="application/javascript")
            elif path.endswith('.css'):
                return FileResponse(str(file_path), media_type="text/css")
            elif path.endswith('.html'):
                return FileResponse(str(file_path), media_type="text/html")
            elif path.endswith('.json'):
                return FileResponse(str(file_path), media_type="application/json")
            elif path.endswith('.png'):
                return FileResponse(str(file_path), media_type="image/png")
            elif path.endswith('.ico'):
                return FileResponse(str(file_path), media_type="image/x-icon")
            else:
                return FileResponse(str(file_path))
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ index.htmlë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (SPA ë¼ìš°íŒ…)
        return FileResponse(str(FLUTTER_WEB_DIR / "index.html"), media_type="text/html")
    
    logger.info("âœ… Flutter ì›¹ ì•± ì„œë¹™ ì„¤ì • ì™„ë£Œ")
else:
    logger.warning(f"âš ï¸ Flutter ì›¹ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FLUTTER_WEB_DIR}")
    
    @app.get("/")
    async def fallback_root():
        return {
            "message": "ëŒ€ì„  ì‹œë®¬ë ˆì´í„° API ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.", 
            "status": "running",
            "flutter_web_dir": str(FLUTTER_WEB_DIR),
            "flutter_web_exists": FLUTTER_WEB_DIR.exists()
        }

# === ì„œë²„ ì‹¤í–‰ ===
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)