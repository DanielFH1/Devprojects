{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e85045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selfies as sf\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 데이터 경로 설정\n",
    "DATA_PATH = './TransGEM/data/subLINCS.csv'\n",
    "\n",
    "# 1. Vocab 구축 및 Tokenizer 함수\n",
    "def build_vocab(smiles_list):\n",
    "    \"\"\"\n",
    "    데이터셋의 모든 SMILES를 SELFIES로 변환하여 등장하는 모든 토큰의 사전을 만듭니다.\n",
    "    [cite: 383] - all unique SELFIES are split into tokens to build a dictionary.\n",
    "    \"\"\"\n",
    "    vocab = set()\n",
    "    max_len = 0\n",
    "    \n",
    "    print(\"Building Vocabulary...\")\n",
    "    for smiles in tqdm(smiles_list):\n",
    "        try:\n",
    "            # SMILES -> SELFIES 변환\n",
    "            selfie = sf.encoder(smiles)\n",
    "            if selfie is None: continue\n",
    "            \n",
    "            # 토큰화 ([C], [O] 등으로 분리)\n",
    "            tokens = list(sf.split_selfies(selfie))\n",
    "            vocab.update(tokens)\n",
    "            max_len = max(max_len, len(tokens))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    # 특수 토큰 추가\n",
    "    vocab = sorted(list(vocab))\n",
    "    token2idx = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "    for i, token in enumerate(vocab):\n",
    "        token2idx[token] = i + 3\n",
    "        \n",
    "    idx2token = {v: k for k, v in token2idx.items()}\n",
    "    \n",
    "    print(f\"Vocab Size: {len(token2idx)}\")\n",
    "    print(f\"Max Sequence Length: {max_len}\")\n",
    "    \n",
    "    return token2idx, idx2token, max_len\n",
    "\n",
    "def smile_to_indices(smiles, token2idx, max_len):\n",
    "    \"\"\"\n",
    "    SMILES를 정수 인덱스 리스트로 변환 (Padding 포함)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        selfie = sf.encoder(smiles)\n",
    "        tokens = list(sf.split_selfies(selfie))\n",
    "        \n",
    "        # <sos> + tokens + <eos>\n",
    "        indices = [token2idx['<sos>']] + [token2idx.get(t, token2idx['<pad>']) for t in tokens] + [token2idx['<eos>']]\n",
    "        \n",
    "        # Padding\n",
    "        if len(indices) < max_len:\n",
    "            indices += [token2idx['<pad>']] * (max_len - len(indices))\n",
    "        else:\n",
    "            indices = indices[:max_len] # 잘라내기\n",
    "            \n",
    "        return indices\n",
    "    except:\n",
    "        return [token2idx['<pad>']] * max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c379c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransGEMDataset(Dataset):\n",
    "    def __init__(self, df, token2idx, max_len):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.token2idx = token2idx\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # 1. Cell Line\n",
    "        self.cell_lines = sorted(df['cell_line'].unique().tolist())\n",
    "        self.cell2idx = {name: i for i, name in enumerate(self.cell_lines)}\n",
    "        \n",
    "        # 2. Gene Column 확인\n",
    "        if 'gene_e' in df.columns:\n",
    "            self.gene_col_name = 'gene_e'\n",
    "            print(f\"✅ 'gene_e' column detected. Parsing 'sep=//' format.\")\n",
    "        else:\n",
    "            # 백업 로직\n",
    "            exclude = ['cell_line', 'dose', 'drug_id', 'smiles', 'selfies', 'pert_id', 'pert_iname', 'pert_type']\n",
    "            self.gene_col_name = [c for c in df.columns if c not in exclude]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def tenfold_binary_embedding(self, value):\n",
    "        \"\"\"논문의 Tenfold Binary Embedding [cite: 288-292]\"\"\"\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except:\n",
    "            value = 0.0\n",
    "        sign_bit = 1 if value > 0 else 0\n",
    "        tenfold_value = int(abs(value) * 10)\n",
    "        binary_str = bin(tenfold_value)[2:].zfill(9)\n",
    "        if len(binary_str) > 9: binary_str = binary_str[-9:] \n",
    "        vec = [sign_bit] + [int(b) for b in binary_str]\n",
    "        return vec\n",
    "\n",
    "    def parse_gene_string(self, gene_str):\n",
    "        \"\"\"\n",
    "        '-0.1//-0.3//...' 형태의 문자열을 파싱하여 float 리스트로 변환\n",
    "        \"\"\"\n",
    "        if isinstance(gene_str, str):\n",
    "            try:\n",
    "                # [수정됨] '//'를 기준으로 자르고, 빈 문자열은 제외\n",
    "                return [float(x) for x in gene_str.split('//') if x.strip()]\n",
    "            except Exception as e:\n",
    "                print(f\"Parsing Error: {e} in string: {gene_str[:50]}...\")\n",
    "                return []\n",
    "        elif isinstance(gene_str, (list, np.ndarray)):\n",
    "            return gene_str\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 1. Cell Line\n",
    "        cell_idx = self.cell2idx.get(row['cell_line'], 0)\n",
    "        \n",
    "        # 2. Gene Expression\n",
    "        if isinstance(self.gene_col_name, str):\n",
    "            raw_gene_data = row[self.gene_col_name]\n",
    "            gene_values = self.parse_gene_string(raw_gene_data)\n",
    "        else:\n",
    "            gene_values = row[self.gene_col_name].values.astype(float)\n",
    "            \n",
    "        # 3. Tenfold Binary Embedding\n",
    "        gene_embeds = []\n",
    "        for val in gene_values:\n",
    "            gene_embeds.extend(self.tenfold_binary_embedding(val))\n",
    "            \n",
    "        gene_tensor = torch.tensor(gene_embeds, dtype=torch.float32)\n",
    "        \n",
    "        # 4. Target (Molecule)\n",
    "        target_indices = smile_to_indices(row['smiles'], self.token2idx, self.max_len)\n",
    "        target_tensor = torch.tensor(target_indices, dtype=torch.long)\n",
    "        \n",
    "        return {\n",
    "            'cell_idx': torch.tensor(cell_idx, dtype=torch.long),\n",
    "            'gene_tensor': gene_tensor, \n",
    "            'target': target_tensor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dddae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Loaded! Shape: (27378, 6)\n",
      "Building Vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27378/27378 [00:10<00:00, 2737.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vocab Size: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import selfies as sf\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 1. 데이터 로드 (df 정의)\n",
    "DATA_PATH = './TransGEM/data/subLINCS.csv'\n",
    "if os.path.exists(DATA_PATH):\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"✅ Data Loaded! Shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"❌ Data file not found!\")\n",
    "\n",
    "# 2. build_vocab 함수 정의 (만약 위쪽 셀에서 실행 안 했다면 필요)\n",
    "def build_vocab(smiles_list):\n",
    "    vocab = set()\n",
    "    print(\"Building Vocabulary...\")\n",
    "    for smiles in tqdm(smiles_list):\n",
    "        try:\n",
    "            selfie = sf.encoder(smiles)\n",
    "            if selfie is None: continue\n",
    "            tokens = list(sf.split_selfies(selfie))\n",
    "            vocab.update(tokens)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    vocab = sorted(list(vocab))\n",
    "    token2idx = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "    for i, token in enumerate(vocab):\n",
    "        token2idx[token] = i + 3\n",
    "    return token2idx\n",
    "\n",
    "# 3. Vocab 생성 (token2idx 정의)\n",
    "# 이 부분이 실행되어야 다음 셀의 token2idx 에러도 안 납니다.\n",
    "if 'df' in locals():\n",
    "    token2idx = build_vocab(df['smiles'].tolist())\n",
    "    print(f\"✅ Vocab Size: {len(token2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8aa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'gene_e' column detected. Parsing 'sep=//' format.\n",
      "\n",
      "✅ Sample Batch Loaded Successfully!\n",
      "Cell Index Shape: torch.Size([4])\n",
      "Gene Tensor Shape: torch.Size([4, 9780])\n",
      "Target Shape: torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "# 2. Dataset & DataLoader 생성\n",
    "# 데이터 로드 시에만 시간이 좀 걸리고, 이후에는 금방 됩니다.\n",
    "dataset = TransGEMDataset(df, token2idx, max_len=100) \n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True) \n",
    "\n",
    "# 3. 샘플 배치 확인\n",
    "try:\n",
    "    sample_batch = next(iter(dataloader))\n",
    "    print(\"\\n✅ Sample Batch Loaded Successfully!\")\n",
    "    print(\"Cell Index Shape:\", sample_batch['cell_idx'].shape)     # [4]\n",
    "    print(\"Gene Tensor Shape:\", sample_batch['gene_tensor'].shape) # [4, 9780] 이어야 함\n",
    "    print(\"Target Shape:\", sample_batch['target'].shape)           # [4, 100]\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading batch: {e}\")\n",
    "    # 디버깅을 위해 첫 번째 행의 컬럼들을 출력해봅니다\n",
    "    print(\"First row columns:\", df.iloc[0].index.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feed5a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- gene_e 컬럼 데이터 샘플 ---\n",
      "값: -0.1//-0.3//-0.2//0.1//0.1//-0.1//-0.2//0.0//0.0//0.1//-0.0//-0.2//-0.0//-0.1//0.4//-0.1//0.0//0.2// ... (생략)\n",
      "타입: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 (이미 되어 있다면 df 변수 사용)\n",
    "# df = pd.read_csv('./TransGEM/data/subLINCS.csv') \n",
    "\n",
    "print(\"--- gene_e 컬럼 데이터 샘플 ---\")\n",
    "sample_gene = df['gene_e'].iloc[0]\n",
    "print(f\"값: {sample_gene[:100]} ... (생략)\") # 앞부분만 출력\n",
    "print(f\"타입: {type(sample_gene)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d198414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [Step 1] Raw Data in CSV (String Format) ===\n",
      "Format Check: -0.1//-0.3//-0.2//0.1//0.1//-0.1//-0.2//0.0//0.0//0.1//-0.0/ ...\n",
      " (Separator: '//' detected)\n",
      "\n",
      "=== [Step 2] Parsed Float Values (978 Genes) ===\n",
      "First 5 Genes: [-0.1, -0.3, -0.2, 0.1, 0.1]\n",
      "Total Gene Count: 978\n",
      "\n",
      "=== [Step 3] Tenfold-Binary Embedding Application ===\n",
      "Ex 1 (Real Data): -0.1 \t---> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Ex 2 (Paper Ex):  7.3 \t---> [1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "                   [Sign] + [9-bit Magnitude]\n",
      "\n",
      "=== [Step 4] Final Input Dimension Expansion ===\n",
      "Original: 978 genes (Floats)\n",
      "Expanded: 978 * 10 = 9780 dimensions (Binary Vector)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. 데이터 로드 (확인을 위해 상위 1개 행만 로드)\n",
    "# 경로가 맞는지 꼭 확인하세요!\n",
    "DATA_PATH = './TransGEM/data/subLINCS.csv'\n",
    "df_sample = pd.read_csv(DATA_PATH, nrows=1)\n",
    "\n",
    "# 2. Raw Data 확인 (특이한 포맷 // 구분자)\n",
    "raw_gene_string = df_sample['gene_e'].iloc[0]\n",
    "print(\"=== [Step 1] Raw Data in CSV (String Format) ===\")\n",
    "print(f\"Format Check: {raw_gene_string[:60]} ...\") \n",
    "print(f\" (Separator: '//' detected)\\n\")\n",
    "\n",
    "# 3. Parsing (문자열 -> 실수 리스트 변환)\n",
    "parsed_values = [float(x) for x in raw_gene_string.split('//') if x.strip()]\n",
    "print(\"=== [Step 2] Parsed Float Values (978 Genes) ===\")\n",
    "print(f\"First 5 Genes: {parsed_values[:5]}\")\n",
    "print(f\"Total Gene Count: {len(parsed_values)}\\n\")\n",
    "\n",
    "# 4. Tenfold-Binary Embedding (핵심 로직 시각화)\n",
    "def tenfold_binary_embedding_demo(value):\n",
    "    sign_bit = 1 if value > 0 else 0\n",
    "    tenfold_value = int(abs(value) * 10)\n",
    "    binary_str = bin(tenfold_value)[2:].zfill(9)\n",
    "    if len(binary_str) > 9: binary_str = binary_str[-9:]\n",
    "    vec = [sign_bit] + [int(b) for b in binary_str]\n",
    "    return vec\n",
    "\n",
    "# 예시 값으로 변환 과정 보여주기\n",
    "sample_val_1 = parsed_values[0]   # 실제 데이터의 첫 번째 값\n",
    "sample_val_2 = 7.3                # 논문 예시 값\n",
    "\n",
    "embed_1 = tenfold_binary_embedding_demo(sample_val_1)\n",
    "embed_2 = tenfold_binary_embedding_demo(sample_val_2)\n",
    "\n",
    "print(\"=== [Step 3] Tenfold-Binary Embedding Application ===\")\n",
    "print(f\"Ex 1 (Real Data): {sample_val_1} \\t---> {embed_1}\")\n",
    "print(f\"Ex 2 (Paper Ex):  {sample_val_2} \\t---> {embed_2}\")\n",
    "print(\"                   [Sign] + [9-bit Magnitude]\\n\")\n",
    "\n",
    "# 5. 최종 차원 확장 확인\n",
    "print(\"=== [Step 4] Final Input Dimension Expansion ===\")\n",
    "print(f\"Original: {len(parsed_values)} genes (Floats)\")\n",
    "print(f\"Expanded: {len(parsed_values)} * 10 = {len(parsed_values) * 10} dimensions (Binary Vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb43f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transgem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
