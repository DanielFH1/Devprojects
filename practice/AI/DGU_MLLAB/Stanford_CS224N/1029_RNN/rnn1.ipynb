{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dba882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (1.21.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (8.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: six in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (2.6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\seungwoo\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635300b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: cpu\n"
     ]
    }
   ],
   "source": [
    "# shakespeare.txtë¼ëŠ” ë°ì´í„°ì…‹ ë‹¤ìš´ë°›ê¸°\n",
    "# 1.1MB, ì•½ 100ë§Œ ê¸€ì\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}')\n",
    "\n",
    "# ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd44901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…°ìµìŠ¤í”¼ì–´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: 1,115,394 ê¸€ì\n",
      "\n",
      "í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# ì…°ìµìŠ¤í”¼ì–´ í…ìŠ¤íŠ¸ë¥¼ ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤\n",
    "print(\"ì…°ìµìŠ¤í”¼ì–´ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "print(f\"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text):,} ê¸€ì\")\n",
    "print(\"\\ní…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
    "print(text[:500])  # ì²˜ìŒ 500ê¸€ì ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfdabbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì–´íœ˜ í¬ê¸°: 65ê°œ ë¬¸ì\n",
      "ë¬¸ì ëª©ë¡: \n",
      " !$&',-.3:;?ABCDEFG...\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, text, seq_length=100):\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # ê³ ìœ í•œ ë¬¸ìë“¤ì„ ì°¾ì•„ì„œ ì •ë ¬\n",
    "        self.chars = sorted(list(set(text)))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        \n",
    "        # ë¬¸ì -> ìˆ«ì, ìˆ«ì -> ë¬¸ì ë³€í™˜ ì‚¬ì „\n",
    "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
    "        \n",
    "        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n",
    "        self.encoded_text = [self.char_to_idx[ch] for ch in text]\n",
    "        \n",
    "        print(f\"ì–´íœ˜ í¬ê¸°: {self.vocab_size}ê°œ ë¬¸ì\")\n",
    "        print(f\"ë¬¸ì ëª©ë¡: {''.join(self.chars[:20])}...\")\n",
    "        \n",
    "    def encode(self, text):\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "        return [self.char_to_idx[ch] for ch in text if ch in self.char_to_idx]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "        return ''.join([self.idx_to_char[i] for i in indices])\n",
    "\n",
    "# ì „ì²˜ë¦¬ ê°ì²´ ìƒì„±\n",
    "preprocessor = TextPreprocessor(text, seq_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bd9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ í•™ìŠµ ìƒ˜í”Œ ìˆ˜: 1,115,294ê°œ\n",
      "ë°°ì¹˜ ìˆ˜: 17,426ê°œ\n"
     ]
    }
   ],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    \"\"\"PyTorchê°€ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, encoded_text, seq_length):\n",
    "        self.encoded_text = encoded_text\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        # ë§Œë“¤ ìˆ˜ ìˆëŠ” ì‹œí€€ìŠ¤ì˜ ê°œìˆ˜\n",
    "        return len(self.encoded_text) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # idxë²ˆì§¸ ì‹œí€€ìŠ¤ì™€ ì •ë‹µ ê°€ì ¸ì˜¤ê¸°\n",
    "        # ì…ë ¥: \"Hell\" â†’ ì •ë‹µ: \"ello\"\n",
    "        x = self.encoded_text[idx:idx + self.seq_length]\n",
    "        y = self.encoded_text[idx + 1:idx + self.seq_length + 1]\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# ë°ì´í„°ì…‹ê³¼ ë°ì´í„°ë¡œë” ìƒì„±\n",
    "seq_length = 100  # í•œ ë²ˆì— í•™ìŠµí•  ë¬¸ì ê¸¸ì´\n",
    "batch_size = 64   # í•œ ë²ˆì— ì²˜ë¦¬í•  ìƒ˜í”Œ ìˆ˜\n",
    "\n",
    "dataset = ShakespeareDataset(preprocessor.encoded_text, seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f\"ì „ì²´ í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(dataset):,}ê°œ\")\n",
    "print(f\"ë°°ì¹˜ ìˆ˜: {len(dataloader):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98129a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ê°„ë‹¨í•œ RNN ëª¨ë¸ ===\n",
      "ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: 123,841ê°œ\n"
     ]
    }
   ],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \"\"\"ê¸°ë³¸ì ì¸ RNN ëª¨ë¸\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 1. ì„ë² ë”© ë ˆì´ì–´: ìˆ«ìë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 2. RNN ë ˆì´ì–´: ìˆœì°¨ì ìœ¼ë¡œ ì •ë³´ ì²˜ë¦¬\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # 3. ì¶œë ¥ ë ˆì´ì–´: ë‹¤ìŒ ë¬¸ì ì˜ˆì¸¡\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x shape: (batch_size, seq_length)\n",
    "        \n",
    "        # ì„ë² ë”© ë³€í™˜\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        \n",
    "        # RNN ì²˜ë¦¬\n",
    "        output, hidden = self.rnn(embedded, hidden)  # (batch_size, seq_length, hidden_dim)\n",
    "        \n",
    "        # ìµœì¢… ì˜ˆì¸¡\n",
    "        output = self.fc(output)  # (batch_size, seq_length, vocab_size)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ ìƒì„±\n",
    "        return torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "rnn_model = SimpleRNN(preprocessor.vocab_size).to(device)\n",
    "print(f\"\\n=== ê°„ë‹¨í•œ RNN ëª¨ë¸ ===\")\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in rnn_model.parameters()):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47940da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LSTM ëª¨ë¸ ===\n",
      "ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: 420,289ê°œ\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM ëª¨ë¸ (ì¥ê¸° ê¸°ì–µë ¥ì´ ë” ì¢‹ìŒ!)\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 1. ì„ë² ë”© ë ˆì´ì–´\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 2. LSTM ë ˆì´ì–´: RNNë³´ë‹¤ ê¸°ì–µë ¥ì´ ì¢‹ìŒ!\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # 3. ì¶œë ¥ ë ˆì´ì–´\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # ì„ë² ë”© ë³€í™˜\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # LSTM ì²˜ë¦¬\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # ìµœì¢… ì˜ˆì¸¡\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # LSTMì€ ë‘ ê°œì˜ ì€ë‹‰ ìƒíƒœë¥¼ ì‚¬ìš© (h, c)\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "lstm_model = LSTMModel(preprocessor.vocab_size).to(device)\n",
    "print(f\"\\n=== LSTM ëª¨ë¸ ===\")\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in lstm_model.parameters()):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d561c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs=10, model_name=\"Model\"):\n",
    "    \"\"\"ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "    criterion = nn.CrossEntropyLoss()  # ë¶„ë¥˜ ë¬¸ì œìš© ì†ì‹¤ í•¨ìˆ˜\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)  # Adam ìµœì í™”\n",
    "    \n",
    "    # í•™ìŠµ ê¸°ë¡ìš©\n",
    "    train_losses = []\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{model_name} í•™ìŠµ ì‹œì‘!\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    model.train()  # í•™ìŠµ ëª¨ë“œ\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            # ë°ì´í„°ë¥¼ GPU/CPUë¡œ ì´ë™\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # 1. ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 2. ìˆœì „íŒŒ (Forward)\n",
    "            output, _ = model(x)\n",
    "            \n",
    "            # 3. ì†ì‹¤ ê³„ì‚°\n",
    "            # output: (batch_size, seq_length, vocab_size)\n",
    "            # y: (batch_size, seq_length)\n",
    "            loss = criterion(output.view(-1, preprocessor.vocab_size), y.view(-1))\n",
    "            \n",
    "            # 4. ì—­ì „íŒŒ (Backward)\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (í­ë°œ ë°©ì§€)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            \n",
    "            # 6. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "            if (batch_idx + 1) % 200 == 0:\n",
    "                print(f\"  ë°°ì¹˜ [{batch_idx+1}/{len(dataloader)}] - ì†ì‹¤: {loss.item():.4f}\")\n",
    "        \n",
    "        # ì—í¬í¬ í‰ê·  ì†ì‹¤\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nì—í¬í¬ [{epoch+1}/{epochs}] - í‰ê·  ì†ì‹¤: {avg_loss:.4f} - ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ\\n\")\n",
    "    \n",
    "    print(f\"{model_name} í•™ìŠµ ì™„ë£Œ! ğŸ‰\\n\")\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c95bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string=\"The \", length=500, temperature=0.8):\n",
    "    \"\"\"í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    model.eval()  # í‰ê°€ ëª¨ë“œ\n",
    "    \n",
    "    # ì‹œì‘ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜\n",
    "    input_eval = preprocessor.encode(start_string)\n",
    "    input_eval = torch.tensor(input_eval, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ì €ì¥\n",
    "    generated_text = start_string\n",
    "    \n",
    "    # ì€ë‹‰ ìƒíƒœ ì´ˆê¸°í™”\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì•ˆ í•¨ (ë¹ ë¦„!)\n",
    "        for _ in range(length):\n",
    "            # ì˜ˆì¸¡\n",
    "            output, hidden = model(input_eval, hidden)\n",
    "            \n",
    "            # ë§ˆì§€ë§‰ ì¶œë ¥ ê°€ì ¸ì˜¤ê¸°\n",
    "            output = output[0, -1, :] / temperature\n",
    "            \n",
    "            # í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜\n",
    "            probabilities = torch.softmax(output, dim=0).cpu().numpy()\n",
    "            \n",
    "            # ë‹¤ìŒ ë¬¸ì ìƒ˜í”Œë§\n",
    "            predicted_idx = np.random.choice(len(probabilities), p=probabilities)\n",
    "            \n",
    "            # ìƒì„±ëœ ë¬¸ì ì¶”ê°€\n",
    "            generated_text += preprocessor.idx_to_char[predicted_idx]\n",
    "            \n",
    "            # ë‹¤ìŒ ì…ë ¥ ì¤€ë¹„\n",
    "            input_eval = torch.tensor([[predicted_idx]], dtype=torch.long).to(device)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb68a3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ê°„ë‹¨í•œ RNN í•™ìŠµ ì‹œì‘!\n",
      "==================================================\n",
      "\n",
      "  ë°°ì¹˜ [200/17426] - ì†ì‹¤: 1.8033\n",
      "  ë°°ì¹˜ [400/17426] - ì†ì‹¤: 1.6214\n",
      "  ë°°ì¹˜ [600/17426] - ì†ì‹¤: 1.5465\n",
      "  ë°°ì¹˜ [800/17426] - ì†ì‹¤: 1.5412\n",
      "  ë°°ì¹˜ [1000/17426] - ì†ì‹¤: 1.5059\n",
      "  ë°°ì¹˜ [1200/17426] - ì†ì‹¤: 1.4825\n",
      "  ë°°ì¹˜ [1400/17426] - ì†ì‹¤: 1.4564\n",
      "  ë°°ì¹˜ [1600/17426] - ì†ì‹¤: 1.4479\n",
      "  ë°°ì¹˜ [1800/17426] - ì†ì‹¤: 1.4438\n",
      "  ë°°ì¹˜ [2000/17426] - ì†ì‹¤: 1.3886\n",
      "  ë°°ì¹˜ [2200/17426] - ì†ì‹¤: 1.4174\n",
      "  ë°°ì¹˜ [2400/17426] - ì†ì‹¤: 1.4468\n",
      "  ë°°ì¹˜ [2600/17426] - ì†ì‹¤: 1.4212\n",
      "  ë°°ì¹˜ [2800/17426] - ì†ì‹¤: 1.3978\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/25483637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# RNN í•™ìŠµ (10 ì—í¬í¬)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrnn_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ê°„ë‹¨í•œ RNN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/2665184996.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs, model_name)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# 4. ì—­ì „íŒŒ (Backward)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# 5. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (í­ë°œ ë°©ì§€)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SeungWoo\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             )\n\u001b[1;32m--> 521\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\SeungWoo\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     _engine_run_backward(\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SeungWoo\\Anaconda3\\lib\\site-packages\\torch\\autograd\\graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RNN í•™ìŠµ (10 ì—í¬í¬)\n",
    "rnn_losses = train_model(rnn_model, dataloader, epochs=10, model_name=\"ê°„ë‹¨í•œ RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM í•™ìŠµ (10 ì—í¬í¬)\n",
    "lstm_losses = train_model(lstm_model, dataloader, epochs=10, model_name=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fde811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¼ì • ë¹„êµ ê·¸ë˜í”„\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(range(1, len(rnn_losses) + 1), rnn_losses, 'b-o', label='ê°„ë‹¨í•œ RNN', linewidth=2, markersize=8)\n",
    "plt.plot(range(1, len(lstm_losses) + 1), lstm_losses, 'r-s', label='LSTM', linewidth=2, markersize=8)\n",
    "\n",
    "plt.xlabel('ì—í¬í¬', fontsize=14)\n",
    "plt.ylabel('í‰ê·  ì†ì‹¤ (Loss)', fontsize=14)\n",
    "plt.title('RNN vs LSTM í•™ìŠµ ê³¡ì„  ë¹„êµ', fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ìµœì¢… ì†ì‹¤ ë¹„êµ\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ìµœì¢… í•™ìŠµ ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RNN ìµœì¢… ì†ì‹¤:  {rnn_losses[-1]:.4f}\")\n",
    "print(f\"LSTM ìµœì¢… ì†ì‹¤: {lstm_losses[-1]:.4f}\")\n",
    "print(f\"ê°œì„ ìœ¨: {((rnn_losses[-1] - lstm_losses[-1]) / rnn_losses[-1] * 100):.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼ ë¹„êµ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì—¬ëŸ¬ ì‹œì‘ ë¬¸ìì—´ë¡œ í…ŒìŠ¤íŠ¸\n",
    "start_strings = [\"ROMEO:\", \"The King \", \"To be or not to be\"]\n",
    "\n",
    "for start_str in start_strings:\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"ì‹œì‘ ë¬¸ìì—´: '{start_str}'\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # RNN ìƒì„±\n",
    "    print(\"ğŸ“ ê°„ë‹¨í•œ RNN ìƒì„±:\")\n",
    "    print(\"-\" * 70)\n",
    "    rnn_text = generate_text(rnn_model, start_string=start_str, length=300, temperature=0.8)\n",
    "    print(rnn_text)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # LSTM ìƒì„±\n",
    "    print(\"ğŸ“ LSTM ìƒì„±:\")\n",
    "    print(\"-\" * 70)\n",
    "    lstm_text = generate_text(lstm_model, start_string=start_str, length=300, temperature=0.8)\n",
    "    print(lstm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ì˜¨ë„(Temperature)ì— ë”°ë¥¸ ìƒì„± ìŠ¤íƒ€ì¼ ë¹„êµ (LSTM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "temperatures = [0.5, 0.8, 1.2]\n",
    "start_string = \"The \"\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"ì˜¨ë„: {temp} {'(ë³´ìˆ˜ì )' if temp < 0.7 else '(ê· í˜•)' if temp < 1.0 else '(ì°½ì˜ì )'}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    text = generate_text(lstm_model, start_string=start_string, length=300, temperature=temp)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89ad1aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/4258332415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Simple RNN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfinal_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrnn_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'#3498db'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#e74c3c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rnn_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performance comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Final loss comparison\n",
    "ax1 = axes[0]\n",
    "models = ['Simple RNN', 'LSTM']\n",
    "final_losses = [rnn_losses[-1], lstm_losses[-1]]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax1.bar(models, final_losses, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('Final Loss (Lower is better)', fontsize=12)\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([min(final_losses) * 0.9, max(final_losses) * 1.1])\n",
    "\n",
    "# Show value above bars\n",
    "for bar, loss in zip(bars, final_losses):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{loss:.4f}',\n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Parameter count comparison\n",
    "ax2 = axes[1]\n",
    "rnn_params = sum(p.numel() for p in rnn_model.parameters())\n",
    "lstm_params = sum(p.numel() for p in lstm_model.parameters())\n",
    "params = [rnn_params, lstm_params]\n",
    "\n",
    "bars2 = ax2.bar(models, params, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Number of Parameters', fontsize=12)\n",
    "ax2.set_title('Model Complexity Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Show value above bars\n",
    "for bar, param in zip(bars2, params):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{param:,}',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ Final Project Summary\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Data\")\n",
    "print(f\"   - Number of training characters: {len(text):,}\")\n",
    "print(f\"   - Vocabulary size: {preprocessor.vocab_size} unique characters\")\n",
    "print(f\"   - Sequence length: {seq_length}\")\n",
    "\n",
    "print(f\"\\n2. Model Comparison\")\n",
    "print(f\"   Simple RNN:\")\n",
    "print(f\"   - Parameters: {rnn_params:,}\")\n",
    "print(f\"   - Final Loss: {rnn_losses[-1]:.4f}\")\n",
    "print(f\"   - Features: Simple structure, short-term memory\")\n",
    "\n",
    "print(f\"\\n   LSTM:\")\n",
    "print(f\"   - Parameters: {lstm_params:,}\")\n",
    "print(f\"   - Final Loss: {lstm_losses[-1]:.4f}\")\n",
    "print(f\"   - Features: Gating mechanism, long-term memory\")\n",
    "print(f\"   - Performance Improvement: {((rnn_losses[-1] - lstm_losses[-1]) / rnn_losses[-1] * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\n3. Conclusion\")\n",
    "print(f\"   âœ… LSTM learns long-term dependencies better\")\n",
    "print(f\"   âœ… Generated text is more coherent and natural\")\n",
    "print(f\"   âœ… Higher complexity, but clear performance gain\")\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25157e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
